{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ptb.zip\r\n",
      "  inflating: ptb/reader.py           \r\n"
     ]
    }
   ],
   "source": [
    "!wget -q -O ptb.zip https://ibm.box.com/shared/static/z2yvmhbskc45xd2a9a4kkn6hg4g4kj5r.zip\n",
    "!unzip -o ptb.zip\n",
    "!cp ptb/reader.py .\n",
    "import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-11-04 17:38:43--  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
      "Resolving www.fit.vutbr.cz (www.fit.vutbr.cz)... 147.229.9.23, 2001:67c:1220:809::93e5:917\n",
      "Connecting to www.fit.vutbr.cz (www.fit.vutbr.cz)|147.229.9.23|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 34869662 (33M) [application/x-gtar]\n",
      "Saving to: ‘simple-examples.tgz’\n",
      "\n",
      "simple-examples.tgz 100%[===================>]  33.25M   110KB/s    in 8m 14s  \n",
      "\n",
      "2017-11-04 17:46:58 (68.9 KB/s) - ‘simple-examples.tgz’ saved [34869662/34869662]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz \n",
    "!tar xzf simple-examples.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_scale = 0.1\n",
    "learning_rate = 1.0\n",
    "max_grad_norm = 5\n",
    "num_layers = 2\n",
    "num_steps = 20\n",
    "hidden_size = 200\n",
    "max_epoch = 4\n",
    "max_max_epoch = 13\n",
    "keep_prob = 1\n",
    "decay = 0.5\n",
    "batch_size = 30\n",
    "vocab_size = 10000\n",
    "is_training = 1\n",
    "data_dir = 'simple-examples/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = reader.ptb_raw_data(data_dir)\n",
    "train_data, valid_data, test_data, _ = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "itera = reader.ptb_iterator(train_data, batch_size, num_steps)\n",
    "first_touple = itera.next()\n",
    "x = first_touple[0]\n",
    "y = first_touple[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9970, 9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984,\n",
       "        9986, 9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995],\n",
       "       [2654,    6,  334, 2886,    4,    1,  233,  711,  834,   11,  130,\n",
       "         123,    7,  514,    2,   63,   10,  514,    8,  605],\n",
       "       [   0, 1071,    4,    0,  185,   24,  368,   20,   31, 3109,  954,\n",
       "          12,    3,   21,    2, 2915,    2,   12,    3,   21]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n",
    "_targets = tf.placeholder(tf.int32, [batch_size, num_steps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {_input_data: x, _targets: y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9970, 9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984,\n",
       "        9986, 9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995],\n",
       "       [2654,    6,  334, 2886,    4,    1,  233,  711,  834,   11,  130,\n",
       "         123,    7,  514,    2,   63,   10,  514,    8,  605],\n",
       "       [   0, 1071,    4,    0,  185,   24,  368,   20,   31, 3109,  954,\n",
       "          12,    3,   21,    2, 2915,    2,   12,    3,   21],\n",
       "       [   3,   71,    4,   27,  246,   60,   11,  215,    4,    1, 1846,\n",
       "           9,    3,   71,  546,    2, 6505,  162,    6,  104],\n",
       "       [  93,   25,    6,  261,  681,  251,    0,  278, 3246,   13,  200,\n",
       "           1,    8,  105, 3360,    1,    4,    0,  536,    4],\n",
       "       [  20,    6,  954,   12,    3,   21,   78,   14,  977,  726,    0,\n",
       "          37,   42,   34,    5,  437,  116,  206,  927,    2],\n",
       "       [  18,  296,    7,  201,   76,    4,  182,  560, 3836,   17,  974,\n",
       "         975,    6,  942,    4,  156,   77, 1570,  288,  644],\n",
       "       [  23, 1238,  899,    5,   25,  201,    4,    0,  434,  642,   55,\n",
       "         201,    4,    0, 2423,    2,    1,    1,    1,  483],\n",
       "       [ 379,  706,    9,  413, 8219,   96,   15,    0, 2185, 1758,    1,\n",
       "           1,   37,   13,  834,    5,  852,  222,    7, 1785],\n",
       "       [   2,  179,  940,  117,   38,   59,  677,   14,    1,   10, 1016,\n",
       "         309,   13, 1077, 6360,   16,   23, 4490,    9,  355],\n",
       "       [3572,    4, 3015, 1347,  536,   13,    6, 3949,    5,  438, 9643,\n",
       "           2,   64,   87,   32,  358, 3672, 4103, 1082,   11],\n",
       "       [  71,  178,    3,    8,    3,    2,    0, 1008,  234,   30, 6400,\n",
       "          10,    0,   98,    9,    1,  338,   13,    5,   25],\n",
       "       [1473,   88,   19, 2578, 6591,    8,  629,  563,    8,  223,  184,\n",
       "         127,   18,    6,  828,    1,    2,    0,  324,  158],\n",
       "       [   1,    1,    2,   18,    0, 1844,    4,   73,   39, 2694,    6,\n",
       "        1709,    2,    7,    0, 6509, 1116,   27,    1,    1],\n",
       "       [1055,    5,   25, 8582,   10,  353,  645,   24,    6,  287,    2,\n",
       "        1006,    0, 8861, 2369,   44,    7,    0,    1,  180],\n",
       "       [  36,  501,    5,    6, 1969,    0,   98,   89, 2254,    0,  312,\n",
       "        1641,    4, 1063,    8,  713,    0,  264,  820,    2],\n",
       "       [  32, 2599,  762, 1875,   26, 1402,   45,  516,    2, 2937,   16,\n",
       "        3355, 2062,  251,    0,  529,   24, 1625,  122,   18],\n",
       "       [ 677,  127,    2,   19,   23, 7800, 3592,   14,   64,   87,   32,\n",
       "         350,    0, 3968,    2,   38,   26,  114,   38,   26],\n",
       "       [  25,   45,  769,    2,   23, 2634, 1096, 1175,   19,    6,    1,\n",
       "         154,   23, 1890,   30,    6,    1,    1,    2,  198],\n",
       "       [7736,  391,    5, 5173,  838,    2,  840,    9, 8716,  537, 4132,\n",
       "        2915,    9,    1,    1,   10, 1268,  175,   32,  184],\n",
       "       [   3,   21,    4,    1,  308,  458,   11,   41,   14, 5718,  102,\n",
       "         824,    1,    2,   14,   59,   50,   12,    3,   21],\n",
       "       [   8,    1,   22,   73,   10,  863,   11,  898,  653,  270,    8,\n",
       "         500,  273, 1559,    2,   14, 3019,    5,  585,   84],\n",
       "       [ 483,  762,   87,  108, 1119,    0,    1,   67,    0, 3296,   26,\n",
       "         591,  174,  127,    2,  108,   26, 9821,   11,    6],\n",
       "       [3885,  582,   81,   17, 1834,    2, 1256,   98,  162,  582,  441,\n",
       "         125,   22, 1652,  172,    4,    3,    3,    8,  206],\n",
       "       [  44,   23,    1,    0, 1704,    4,    1,    2,   22,  373,   38,\n",
       "         275,    1, 8017,    2, 2785, 3659, 4359,   80,  634],\n",
       "       [1896,    8,   13, 9468,   17,  752, 4622,    2,   29, 2221,    0,\n",
       "         446, 3552,    4,    0, 2495,  431,  134,  284,  152],\n",
       "       [  48,    7, 1741,  193,    8,  446,  165,  301, 6521, 5122,   15,\n",
       "          12,    3,   21,    4,   10,  161,  783,    8,   79],\n",
       "       [  47, 4447, 1431,    4, 6967, 2121,   24,  452,   18,   43,    3,\n",
       "          48, 1076,   12,    3,   21,   69,   40,    2, 1323],\n",
       "       [  31, 3374,    4, 2108,    1,  134,    8, 6967, 1825, 3306,   14,\n",
       "          13, 3581,    5, 2424, 1583, 6495,    5,    6, 1136],\n",
       "       [  59, 2070, 2433,   28,  517,   20,   23, 4306,    6,   40,  195,\n",
       "           2, 9398,  400, 4908,  673, 1572,  400,    1, 1173]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(_input_data, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(hidden_size, forget_bias=0.0)\n",
    "stacked_lstm = tf.contrib.rnn.MultiRNNCell([lstm_cell] * num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros:0' shape=(30, 200) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(30, 200) dtype=float32>),\n",
       " LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros:0' shape=(30, 200) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros_1:0' shape=(30, 200) dtype=float32>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_initial_state = stacked_lstm.zero_state(batch_size, tf.float32)\n",
    "_initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), h=array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)),\n",
       " LSTMStateTuple(c=array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), h=array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(_initial_state, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = tf.get_variable(\"embedding\", [vocab_size, hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00906066, -0.00329552, -0.00553765, ..., -0.02034925,\n",
       "        -0.00844512, -0.02259792],\n",
       "       [-0.0135624 , -0.02340167,  0.00296221, ...,  0.00993013,\n",
       "         0.00892542,  0.01307555],\n",
       "       [ 0.02065075,  0.01868692,  0.01685954, ..., -0.00653633,\n",
       "         0.00785967,  0.00919427],\n",
       "       ..., \n",
       "       [ 0.0195734 , -0.0189447 ,  0.02025482, ...,  0.00244854,\n",
       "         0.00244354,  0.0098419 ],\n",
       "       [-0.00196924,  0.00678424, -0.00997285, ...,  0.02362626,\n",
       "        -0.00347339,  0.00248653],\n",
       "       [ 0.00758081,  0.01336546, -0.00324182, ..., -0.02079004,\n",
       "        -0.02186598,  0.0055558 ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(embedding, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup_1:0' shape=(30, 20, 200) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.nn.embedding_lookup(embedding, _input_data)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  1.67964138e-02,   6.04799762e-03,   3.67469154e-03, ...,\n",
       "          -2.31846496e-02,  -2.35308018e-02,   2.31233612e-02],\n",
       "        [  1.70437917e-02,  -1.68737285e-02,   1.65801719e-02, ...,\n",
       "          -6.49345852e-03,  -1.76758058e-02,  -7.16558099e-03],\n",
       "        [ -2.78907269e-03,   2.24714763e-02,  -8.70266929e-04, ...,\n",
       "          -5.82855195e-03,  -5.43070957e-03,   9.72737372e-03],\n",
       "        ..., \n",
       "        [ -6.03762455e-03,   1.20601244e-02,   2.34784223e-02, ...,\n",
       "          -2.60634534e-03,  -7.91697018e-03,   1.48015991e-02],\n",
       "        [  1.42990276e-02,  -3.15339863e-03,  -2.16326732e-02, ...,\n",
       "          -3.13481316e-04,  -2.25667264e-02,  -7.28997961e-03],\n",
       "        [  1.88183822e-02,   9.77063179e-03,   2.39017792e-02, ...,\n",
       "           1.05959177e-02,  -1.15640629e-02,  -1.07815862e-02]],\n",
       "\n",
       "       [[ -1.58276502e-02,  -1.05403922e-03,  -1.39244851e-02, ...,\n",
       "           1.60852969e-02,   1.08305477e-02,   1.87126920e-03],\n",
       "        [  1.55343451e-02,   1.68615095e-02,  -2.20092870e-02, ...,\n",
       "          -2.06293110e-02,   1.73071139e-02,  -1.47222737e-02],\n",
       "        [  1.87274292e-02,   1.83967873e-02,   1.07682124e-02, ...,\n",
       "          -1.20905042e-03,   1.97203085e-02,   1.50253288e-02],\n",
       "        ..., \n",
       "        [  1.62154138e-02,  -1.69417523e-02,   1.20137334e-02, ...,\n",
       "           4.06246632e-03,   1.38266906e-02,   1.38014033e-02],\n",
       "        [  1.01467483e-02,   2.25225575e-02,   2.27972344e-02, ...,\n",
       "           1.74429268e-02,  -2.25398690e-05,   2.03736909e-02],\n",
       "        [ -8.79481249e-03,  -8.10604729e-03,   8.31222907e-03, ...,\n",
       "          -9.06874053e-03,  -1.23445848e-02,  -1.50947645e-02]],\n",
       "\n",
       "       [[ -9.06065665e-03,  -3.29552218e-03,  -5.53764589e-03, ...,\n",
       "          -2.03492530e-02,  -8.44512135e-03,  -2.25979220e-02],\n",
       "        [  1.11223944e-02,   1.91149823e-02,  -1.39259072e-02, ...,\n",
       "          -1.36253675e-02,   2.09677964e-02,   9.25619900e-03],\n",
       "        [  8.89111310e-03,  -2.15072110e-02,   1.66504532e-02, ...,\n",
       "           1.86954811e-02,  -2.10411008e-02,  -2.10485421e-02],\n",
       "        ..., \n",
       "        [  1.48019493e-02,   2.28486694e-02,  -5.29713370e-03, ...,\n",
       "          -5.80998324e-03,  -1.29018323e-02,  -1.14574796e-02],\n",
       "        [  1.99776180e-02,   1.19099841e-02,   7.10342452e-03, ...,\n",
       "           7.97691941e-03,  -3.74215096e-03,   1.42530017e-02],\n",
       "        [  2.18838006e-02,  -9.07903910e-03,  -8.69976543e-03, ...,\n",
       "           1.11558586e-02,   2.42272764e-02,   1.00341178e-02]],\n",
       "\n",
       "       ..., \n",
       "       [[ -2.13597622e-02,   1.58870071e-02,   1.76521726e-02, ...,\n",
       "          -1.82930604e-02,  -2.31514573e-02,   2.35055499e-02],\n",
       "        [  7.17220828e-03,   4.19777073e-03,   4.83230129e-03, ...,\n",
       "           5.85837290e-03,  -1.12119950e-02,   4.27356176e-03],\n",
       "        [  4.63093817e-03,  -2.05069594e-02,   2.15097480e-02, ...,\n",
       "          -1.71175990e-02,   7.89858401e-03,  -1.20744957e-02],\n",
       "        ..., \n",
       "        [  1.16761960e-02,   2.96146050e-03,   2.25378349e-02, ...,\n",
       "           1.65389851e-03,   6.56105578e-03,   1.77142099e-02],\n",
       "        [  2.06507482e-02,   1.86869167e-02,   1.68595389e-02, ...,\n",
       "          -6.53633475e-03,   7.85967335e-03,   9.19427350e-03],\n",
       "        [  2.06908435e-02,  -1.29324803e-02,   1.22257955e-02, ...,\n",
       "           1.14964135e-03,  -2.95121409e-03,  -1.44995749e-04]],\n",
       "\n",
       "       [[ -2.31380202e-02,   1.34857446e-02,   1.88814811e-02, ...,\n",
       "           2.05746032e-02,   1.37418285e-02,   1.23183019e-02],\n",
       "        [ -3.79741378e-03,   3.85662727e-03,  -2.15640105e-02, ...,\n",
       "          -4.59757261e-03,  -1.19474661e-02,   2.22562402e-02],\n",
       "        [  8.89111310e-03,  -2.15072110e-02,   1.66504532e-02, ...,\n",
       "           1.86954811e-02,  -2.10411008e-02,  -2.10485421e-02],\n",
       "        ..., \n",
       "        [ -4.57828864e-04,   1.18012726e-02,  -1.14905965e-02, ...,\n",
       "          -1.08094001e-02,   2.33259387e-02,   1.32992715e-02],\n",
       "        [  1.55343451e-02,   1.68615095e-02,  -2.20092870e-02, ...,\n",
       "          -2.06293110e-02,   1.73071139e-02,  -1.47222737e-02],\n",
       "        [  2.07886435e-02,  -6.78084791e-04,  -2.25318465e-02, ...,\n",
       "          -8.09399039e-03,   1.72013938e-02,  -1.91342570e-02]],\n",
       "\n",
       "       [[ -1.89330895e-02,  -7.01249577e-03,  -1.89622790e-02, ...,\n",
       "           1.70127451e-02,   2.20481977e-02,  -6.54639117e-03],\n",
       "        [ -1.21300770e-02,  -1.96778066e-02,  -4.72015142e-03, ...,\n",
       "          -8.40555690e-03,   2.20746994e-02,   6.04434870e-03],\n",
       "        [ -3.73665057e-03,  -2.28106547e-02,  -1.12690451e-02, ...,\n",
       "          -3.70200723e-04,  -2.27233153e-02,  -2.00355873e-02],\n",
       "        ..., \n",
       "        [  3.24867293e-03,  -1.84558835e-02,   1.98350772e-02, ...,\n",
       "          -1.73938293e-02,   4.11053002e-03,  -3.42277065e-03],\n",
       "        [ -1.35624027e-02,  -2.34016664e-02,   2.96221301e-03, ...,\n",
       "           9.93013009e-03,   8.92542303e-03,   1.30755492e-02],\n",
       "        [  1.52559876e-02,  -1.77958049e-02,   2.09517963e-03, ...,\n",
       "          -1.28630782e-02,   5.30709699e-03,   1.83346532e-02]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(inputs, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, new_state = tf.nn.dynamic_rnn(stacked_lstm, inputs, initial_state=_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/transpose:0' shape=(30, 20, 200) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.28038014e-04,  -1.54598078e-04,  -2.23755138e-04, ...,\n",
       "          1.31361288e-04,   3.81200080e-04,  -1.93477099e-04],\n",
       "       [  4.21532139e-04,  -5.36276842e-04,  -3.43302730e-04, ...,\n",
       "         -1.64015437e-04,   3.11073127e-05,   1.62047785e-04],\n",
       "       [  2.19064677e-04,  -9.08020302e-04,  -5.33197599e-04, ...,\n",
       "         -1.90871579e-04,   1.66135971e-04,   1.03238155e-04],\n",
       "       ..., \n",
       "       [  5.16143336e-04,   7.49433239e-04,  -9.26515844e-04, ...,\n",
       "          2.30391947e-06,  -1.62321463e-04,  -1.47921892e-04],\n",
       "       [ -3.53590513e-05,   3.48488713e-04,  -2.59241526e-04, ...,\n",
       "         -3.10192583e-04,  -1.11888701e-04,  -1.86219258e-04],\n",
       "       [  3.04918678e-04,   1.22855810e-04,   4.30091750e-05, ...,\n",
       "         -3.18346662e-04,   1.52440436e-04,  -9.93545909e-05]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(outputs[0], feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(600, 200) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tf.reshape(outputs, [-1, size])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.28038014e-04,  -1.54598078e-04,  -2.23755138e-04,\n",
       "        -4.30595101e-05,   2.87399773e-04,   3.98448727e-04,\n",
       "         3.37762147e-04,   5.00889088e-04,  -6.55235723e-04,\n",
       "         1.18344484e-04,   4.16582297e-05,   8.98258222e-05,\n",
       "         1.59812596e-04,   5.28699777e-04,  -4.01756668e-04,\n",
       "         6.15715035e-05,  -2.43000395e-04,   1.68175015e-04,\n",
       "         2.97444727e-04,  -1.15601419e-04,   2.00428447e-04,\n",
       "        -3.18484061e-04,  -1.23442136e-04,   8.82714157e-05,\n",
       "        -2.53288483e-04,   6.17238175e-06,   9.15494820e-05,\n",
       "         6.16208592e-04,   1.09454006e-04,  -1.86660836e-05,\n",
       "         3.02071392e-04,   2.31553728e-04,  -4.11320652e-05,\n",
       "        -3.40584724e-04,  -9.20751845e-05,   6.42587023e-04,\n",
       "        -2.33502040e-04,   6.70039677e-04,   2.74759135e-04,\n",
       "         7.81209455e-05,  -4.17372939e-04,   2.55408697e-04,\n",
       "        -7.72851490e-05,   3.90585665e-05,  -1.73624197e-04,\n",
       "         2.63542515e-05,   2.42905026e-05,  -4.08513006e-04,\n",
       "        -3.78451456e-04,   6.99399025e-05,   3.51069961e-04,\n",
       "         3.67671193e-04,   3.93157941e-04,   4.13524860e-04,\n",
       "         7.33542431e-04,   1.30839203e-03,   7.21317929e-06,\n",
       "        -1.77872047e-04,   3.35763834e-05,   4.64878016e-04,\n",
       "        -1.92522748e-05,  -2.52297614e-04,  -5.07601711e-04,\n",
       "        -1.68299492e-04,  -5.58571119e-05,  -2.18401881e-04,\n",
       "        -7.03919795e-04,  -2.79830507e-04,   2.02745854e-04,\n",
       "        -2.62950256e-04,   1.99732487e-04,   3.37615464e-04,\n",
       "        -2.30182064e-04,  -8.25042007e-05,   1.93526605e-04,\n",
       "        -2.99508567e-04,   6.67086206e-05,  -1.34380214e-04,\n",
       "        -3.18613602e-04,  -4.05299797e-04,   1.83357702e-06,\n",
       "        -1.52030007e-05,   8.66017726e-05,  -2.40035661e-04,\n",
       "        -1.28624524e-04,  -2.23831390e-04,   2.17507069e-04,\n",
       "         5.14311425e-04,   1.03005033e-04,  -5.47556847e-04,\n",
       "        -6.88330401e-05,  -2.29018144e-04,   2.11799095e-04,\n",
       "        -1.64141413e-04,   3.44292232e-04,   3.16435209e-04,\n",
       "         4.51926666e-04,  -5.51824050e-05,  -7.64599827e-06,\n",
       "        -6.36344921e-05,   2.60963520e-06,  -4.18155629e-04,\n",
       "        -6.18181875e-05,   1.74381523e-04,   2.02203286e-04,\n",
       "         8.17456748e-05,  -5.58886328e-04,   8.53262609e-05,\n",
       "        -3.79550943e-06,  -1.59101168e-04,  -1.64955403e-04,\n",
       "         4.75405075e-04,  -7.10225213e-05,  -3.11366719e-04,\n",
       "         2.39679386e-04,   1.82554577e-04,  -1.13041890e-04,\n",
       "        -3.27205722e-04,   2.10651240e-04,   1.80355608e-04,\n",
       "         3.33409262e-04,  -9.85576662e-06,  -2.29081503e-04,\n",
       "        -1.89007449e-04,   5.88939001e-05,   1.88766062e-04,\n",
       "        -2.74761696e-04,  -1.39627256e-04,   2.53264880e-05,\n",
       "        -3.01852124e-04,  -3.04867299e-05,   9.98355972e-05,\n",
       "         5.48379787e-04,  -1.81664698e-04,  -5.32016275e-04,\n",
       "        -5.22401679e-05,   2.52626982e-04,   3.37639853e-04,\n",
       "         6.13844313e-05,   3.51813360e-04,  -1.21067038e-04,\n",
       "         1.09348948e-04,  -3.32753727e-04,  -3.37194215e-05,\n",
       "        -2.22227682e-04,  -4.63134820e-05,  -9.54093703e-05,\n",
       "         2.80773209e-04,  -2.18601825e-04,  -3.13580269e-04,\n",
       "         3.50567454e-04,   1.28220810e-04,  -1.33843438e-04,\n",
       "        -1.39861688e-04,   4.23887286e-05,  -5.31777157e-04,\n",
       "        -1.04787185e-04,   7.02344405e-05,  -8.08335244e-05,\n",
       "         1.80043731e-04,  -1.82523610e-04,  -2.14353582e-04,\n",
       "         2.16483808e-04,   3.62363993e-04,  -1.81633121e-04,\n",
       "         9.88253159e-05,  -5.91129996e-04,  -7.87753597e-05,\n",
       "        -4.71360981e-04,  -2.69009091e-04,  -6.29045768e-04,\n",
       "        -4.35179572e-05,   4.76523623e-04,   1.10587309e-04,\n",
       "         7.83625001e-04,  -2.39130713e-05,  -3.54403775e-04,\n",
       "         4.13766335e-04,   1.02667116e-04,  -2.99393287e-04,\n",
       "        -4.95755579e-04,   2.22080780e-05,   1.21839825e-04,\n",
       "         2.51491711e-05,   1.35419614e-04,  -3.91665926e-05,\n",
       "        -1.99754053e-04,  -2.40455120e-04,   3.17701051e-04,\n",
       "        -3.04400950e-04,   2.37942601e-04,   7.34220885e-05,\n",
       "        -4.57674934e-04,   5.62301953e-04,   8.61348162e-05,\n",
       "         3.40055658e-06,   4.39400261e-04,   1.31361288e-04,\n",
       "         3.81200080e-04,  -1.93477099e-04], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(output[0], feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_w = tf.get_variable(\"softmax_w\", [size, vocab_size])\n",
    "softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "logits = tf.matmul(output, softmax_w) + softmax_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 10000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "logi = sess.run(logits, feed_dict)\n",
    "logi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "First_word_output_probablity = logi[0]\n",
    "First_word_output_probablity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_array= sess.run(embedding, feed_dict)\n",
    "np.argmax(First_word_output_probablity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9971"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_1:0' shape=(30, 20) dtype=int32>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ = sess.run(tf.reshape(_targets, [-1]), feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9971"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_word_target_code= targ[0]\n",
    "first_word_target_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.16102127e-02,   6.87938184e-04,   1.35919154e-02,\n",
       "        -9.15668067e-03,  -1.73601173e-02,  -2.27504596e-02,\n",
       "        -2.36110222e-02,  -9.64871980e-03,  -2.38232315e-05,\n",
       "        -2.14822870e-02,  -2.99604051e-03,  -1.84585601e-02,\n",
       "        -3.97298858e-03,  -1.47828683e-02,   1.78000480e-02,\n",
       "        -1.53268687e-02,  -3.24980542e-03,   1.68571621e-02,\n",
       "        -1.21433996e-02,  -1.55734057e-02,  -1.91677269e-02,\n",
       "         2.15151720e-03,   1.75487958e-02,   1.33664720e-02,\n",
       "         1.51764639e-02,   9.49978828e-04,  -7.40322471e-03,\n",
       "        -1.52030187e-02,   1.88679211e-02,   2.34593861e-02,\n",
       "         1.90546215e-02,   8.19662586e-03,   2.04088427e-02,\n",
       "         2.06931569e-02,  -3.40806693e-03,  -1.37669221e-03,\n",
       "        -2.19533760e-02,   9.54299793e-03,   4.05992195e-03,\n",
       "        -2.38196198e-02,   1.12132505e-02,  -2.06005778e-02,\n",
       "        -9.28800181e-03,  -9.38421115e-03,   2.00445801e-02,\n",
       "        -1.38140107e-02,   2.33827941e-02,   6.71463273e-03,\n",
       "         1.33269206e-02,   8.89712945e-03,   9.63259488e-04,\n",
       "        -1.48393400e-02,   2.10715048e-02,  -5.42678311e-03,\n",
       "         3.57036479e-03,   9.35843959e-03,  -2.25903410e-02,\n",
       "        -1.37894172e-02,   4.16931510e-03,  -8.62268358e-03,\n",
       "        -8.32713023e-03,  -1.13196019e-02,  -5.71374036e-03,\n",
       "         1.37284994e-02,  -1.40930619e-02,  -1.69910658e-02,\n",
       "        -2.17186101e-03,  -3.33085284e-03,  -9.05671902e-03,\n",
       "         1.55521594e-02,   2.32832022e-02,  -1.80141926e-02,\n",
       "         1.76395550e-02,  -1.63476765e-02,   1.54465586e-02,\n",
       "         1.13388859e-02,   1.35036521e-02,   5.14030084e-03,\n",
       "        -1.80047154e-02,  -6.67538680e-03,   4.80002910e-03,\n",
       "        -2.39233244e-02,   5.25420532e-03,   9.96775180e-03,\n",
       "         1.72333717e-02,  -2.20130291e-02,  -2.06812266e-02,\n",
       "         7.59316236e-03,   2.14510895e-02,  -1.21626789e-02,\n",
       "         1.01139396e-02,   1.80776045e-02,   3.82607244e-03,\n",
       "        -2.08624844e-02,   1.64063163e-02,  -1.89117119e-02,\n",
       "        -1.62558556e-02,   2.09948048e-03,   1.65125169e-02,\n",
       "         1.70666724e-02,  -2.01213136e-02,  -3.11888382e-03,\n",
       "         1.21336728e-02,  -1.25942156e-02,  -1.70761906e-02,\n",
       "         1.15065165e-02,   4.71911579e-03,   8.11177865e-03,\n",
       "         6.30660169e-03,   7.98019767e-03,   1.94265321e-03,\n",
       "        -1.37451105e-03,   2.50969082e-03,   2.40246207e-02,\n",
       "        -4.39626724e-03,   2.23696455e-02,   2.50493176e-03,\n",
       "         1.24242231e-02,  -1.43903922e-02,  -6.18207641e-03,\n",
       "        -5.92371449e-03,   8.99610668e-03,   1.62631720e-02,\n",
       "        -8.25823657e-03,  -2.32630074e-02,  -1.22895297e-02,\n",
       "        -4.37364541e-03,   2.21422426e-02,   2.36637816e-02,\n",
       "         1.93381868e-02,  -1.42629230e-02,  -1.23671079e-02,\n",
       "         9.28403437e-03,   8.73884931e-03,   1.86787061e-02,\n",
       "         1.28068626e-02,   2.00070441e-03,  -2.13927291e-02,\n",
       "         7.25725666e-03,   1.21876597e-03,   8.62260908e-03,\n",
       "         7.83610716e-03,  -1.36627806e-02,  -1.70031525e-02,\n",
       "         6.85383007e-03,   1.15316883e-02,  -1.25608677e-02,\n",
       "        -2.59824470e-03,   1.26793571e-02,  -7.43043050e-03,\n",
       "        -1.45415403e-03,  -6.93116523e-03,  -1.97800063e-02,\n",
       "         8.55420157e-03,   2.23416090e-03,  -1.82179920e-03,\n",
       "         4.79388982e-03,  -5.25867380e-03,   7.14927539e-03,\n",
       "        -1.71318762e-02,   1.14483014e-03,  -7.73626193e-03,\n",
       "        -1.45876976e-02,   2.21510790e-03,   7.04959035e-03,\n",
       "        -2.40284726e-02,   1.66304037e-03,   1.05137192e-02,\n",
       "        -1.64315403e-02,  -1.02414256e-02,   3.17452848e-03,\n",
       "         1.49206594e-02,   2.06927806e-02,  -1.83527116e-02,\n",
       "         9.84923914e-03,   1.36646181e-02,   1.00025721e-03,\n",
       "        -3.78669798e-03,   1.22681223e-02,  -2.24223137e-02,\n",
       "        -1.85418911e-02,   8.35613906e-03,   7.95998052e-03,\n",
       "         1.20015815e-03,   1.21626556e-02,  -2.28422564e-02,\n",
       "         7.20356032e-03,  -1.52355917e-02,  -1.40189193e-03,\n",
       "         3.54275852e-03,   4.34360653e-03,  -9.11331177e-03,\n",
       "        -2.24490762e-02,   1.65621787e-02,  -1.61736533e-02,\n",
       "        -1.11919083e-03,   9.85606387e-03,  -2.00034827e-02,\n",
       "         1.63928308e-02,   2.30728053e-02], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_word_target_vec = sess.run( tf.nn.embedding_lookup(embedding, targ[0]))\n",
    "first_word_target_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits], [tf.reshape(_targets, [-1])],\n",
    "                                                          [tf.ones([batch_size * num_steps])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.209795  ,  9.19322109,  9.22111416,  9.20602989,  9.20452595,\n",
       "        9.22083569,  9.1954174 ,  9.19686031,  9.20719433,  9.20785236,\n",
       "        9.20558262,  9.20939541,  9.20329762,  9.21273327,  9.22187519,\n",
       "        9.1957798 ,  9.2058115 ,  9.21580887,  9.21448898,  9.20135212,\n",
       "        9.19718266,  9.22429657,  9.20598316,  9.20951748,  9.21904373,\n",
       "        9.21196175,  9.21808147,  9.21766853,  9.20844078,  9.19355202,\n",
       "        9.20308113,  9.21794701,  9.22441101,  9.21420383,  9.19382095,\n",
       "        9.21950531,  9.22440243,  9.20244026,  9.19492435,  9.22144222,\n",
       "        9.21341038,  9.20955086,  9.1952858 ,  9.22290039,  9.2253418 ,\n",
       "        9.22757912,  9.19557858,  9.20654678,  9.21790504,  9.20382881,\n",
       "        9.19907951,  9.21344376,  9.19389057,  9.21405125,  9.21518993,\n",
       "        9.21413231,  9.19872665,  9.21329308,  9.19393826,  9.20961189,\n",
       "        9.20711708,  9.20951176,  9.21288967,  9.19982243,  9.21474075,\n",
       "        9.20830917,  9.21098518,  9.20942974,  9.2189188 ,  9.21122169,\n",
       "        9.20828247,  9.21355915,  9.20706081,  9.19462013,  9.2140379 ,\n",
       "        9.21968651,  9.19299507,  9.1972332 ,  9.21074772,  9.20785904,\n",
       "        9.20177746,  9.19727135,  9.20826149,  9.22606564,  9.21947193,\n",
       "        9.1952095 ,  9.20916939,  9.19510078,  9.2015686 ,  9.19346905,\n",
       "        9.21906757,  9.20280552,  9.22110748,  9.21888638,  9.21883965,\n",
       "        9.2094841 ,  9.19522285,  9.22736645,  9.20957565,  9.21899223,\n",
       "        9.19713688,  9.20368195,  9.1991148 ,  9.21342373,  9.193923  ,\n",
       "        9.22639179,  9.19981194,  9.1940546 ,  9.22716904,  9.1954155 ,\n",
       "        9.20911121,  9.20206642,  9.21618176,  9.22074509,  9.22505474,\n",
       "        9.22546864,  9.20078564,  9.19435215,  9.21428299,  9.21794415,\n",
       "        9.21271133,  9.21803474,  9.22027016,  9.21537209,  9.20940113,\n",
       "        9.19687366,  9.20243359,  9.20626163,  9.22425652,  9.22628975,\n",
       "        9.21368122,  9.19724274,  9.20252609,  9.20956612,  9.21677208,\n",
       "        9.20731258,  9.21151161,  9.21705723,  9.2105751 ,  9.21423817,\n",
       "        9.22503853,  9.21714878,  9.22069168,  9.2016573 ,  9.22028542,\n",
       "        9.20943451,  9.19516373,  9.20977688,  9.20113564,  9.19466114,\n",
       "        9.22035789,  9.2095089 ,  9.19527626,  9.21039104,  9.2141943 ,\n",
       "        9.21891499,  9.21903038,  9.21913815,  9.20858574,  9.21411514,\n",
       "        9.21860409,  9.20834351,  9.22549248,  9.19422626,  9.22218227,\n",
       "        9.2212019 ,  9.19519234,  9.19415188,  9.22160053,  9.2189188 ,\n",
       "        9.21900463,  9.2093544 ,  9.20152569,  9.21780682,  9.22061634,\n",
       "        9.22392368,  9.1952219 ,  9.21794796,  9.21615696,  9.21344662,\n",
       "        9.2132206 ,  9.21150017,  9.2269392 ,  9.20831966,  9.22109413,\n",
       "        9.19753742,  9.19978714,  9.21897411,  9.21985531,  9.21734905,\n",
       "        9.2028513 ,  9.20151806,  9.19710636,  9.20079994,  9.19673634,\n",
       "        9.20321369,  9.20459938,  9.20832539,  9.20410442,  9.1965332 ,\n",
       "        9.20941353,  9.21132755,  9.22121811,  9.22740459,  9.20167351,\n",
       "        9.19710732,  9.20331383,  9.22081566,  9.21340752,  9.20923233,\n",
       "        9.21392155,  9.22245216,  9.19394112,  9.20505428,  9.22296333,\n",
       "        9.22162056,  9.19343567,  9.21311569,  9.20843124,  9.21036243,\n",
       "        9.22390652,  9.21340179,  9.20264149,  9.21345043,  9.21410847,\n",
       "        9.19529247,  9.22523499,  9.22645473,  9.19584942,  9.21762085,\n",
       "        9.21965694,  9.19524384,  9.21035194,  9.20817566,  9.21902466,\n",
       "        9.19910049,  9.20163441,  9.22059631,  9.20162296,  9.21401501,\n",
       "        9.20198917,  9.1967907 ,  9.19724274,  9.19652176,  9.20270157,\n",
       "        9.20952606,  9.22637272,  9.20256138,  9.19828415,  9.2164011 ,\n",
       "        9.20052338,  9.2050333 ,  9.19742012,  9.22109413,  9.21886253,\n",
       "        9.21402168,  9.19535923,  9.22346973,  9.22490406,  9.20851612,\n",
       "        9.2189579 ,  9.2141304 ,  9.20501232,  9.19529247,  9.20078373,\n",
       "        9.20956802,  9.19462395,  9.21641541,  9.21138668,  9.19705486,\n",
       "        9.20939064,  9.21418285,  9.218009  ,  9.19531631,  9.22456264,\n",
       "        9.20236301,  9.21296692,  9.21885204,  9.21897411,  9.21910763,\n",
       "        9.22071171,  9.20155907,  9.22339439,  9.21972656,  9.20952606,\n",
       "        9.19830418,  9.22537613,  9.19720936,  9.21645164,  9.214118  ,\n",
       "        9.2206192 ,  9.19528675,  9.20908165,  9.20424747,  9.20008755,\n",
       "        9.21782303,  9.19526196,  9.21895504,  9.22768688,  9.22656536,\n",
       "        9.22498322,  9.22064018,  9.19707489,  9.19664669,  9.19527817,\n",
       "        9.21039009,  9.19318008,  9.20546722,  9.19533443,  9.19702435,\n",
       "        9.22593594,  9.20953083,  9.21231937,  9.20283699,  9.21627045,\n",
       "        9.19519806,  9.2092905 ,  9.19681549,  9.21422291,  9.20872974,\n",
       "        9.2153759 ,  9.20674038,  9.19678593,  9.22556973,  9.20045567,\n",
       "        9.21230602,  9.19347382,  9.21409512,  9.22742462,  9.19672489,\n",
       "        9.22011757,  9.21905518,  9.21913624,  9.19520473,  9.21283531,\n",
       "        9.22528744,  9.19866753,  9.21781731,  9.20487022,  9.19742489,\n",
       "        9.20080185,  9.21412086,  9.19674969,  9.20347881,  9.19787312,\n",
       "        9.20402145,  9.19986439,  9.22227287,  9.19373226,  9.20509529,\n",
       "        9.22556973,  9.19531345,  9.224967  ,  9.21406651,  9.20859337,\n",
       "        9.22549438,  9.21751308,  9.20853233,  9.22553349,  9.21412086,\n",
       "        9.21226692,  9.21048546,  9.21411037,  9.20334244,  9.20785522,\n",
       "        9.22721291,  9.21960163,  9.19669533,  9.19717121,  9.21885395,\n",
       "        9.20599747,  9.20331573,  9.22430611,  9.19578266,  9.1970396 ,\n",
       "        9.21877289,  9.2189064 ,  9.21412468,  9.19607639,  9.22541714,\n",
       "        9.19356155,  9.22064972,  9.20282841,  9.21104622,  9.21393013,\n",
       "        9.2174778 ,  9.20828342,  9.19803715,  9.19918728,  9.21822834,\n",
       "        9.21526527,  9.20825481,  9.21881199,  9.21894932,  9.21962929,\n",
       "        9.19884872,  9.21007824,  9.20486069,  9.21664333,  9.20166683,\n",
       "        9.19396877,  9.20956707,  9.21885395,  9.22671986,  9.2143898 ,\n",
       "        9.20840549,  9.21456814,  9.19976997,  9.21251011,  9.22692013,\n",
       "        9.1994009 ,  9.21903896,  9.21395874,  9.19960117,  9.22121811,\n",
       "        9.22638607,  9.19915104,  9.21345329,  9.19397163,  9.20967197,\n",
       "        9.21881485,  9.22163582,  9.19462013,  9.21954536,  9.21083164,\n",
       "        9.20831013,  9.22067833,  9.21939754,  9.20911121,  9.20258904,\n",
       "        9.22647285,  9.21227551,  9.20235252,  9.21414089,  9.19967175,\n",
       "        9.21904564,  9.22079563,  9.20449162,  9.20819378,  9.21990967,\n",
       "        9.20691395,  9.1937542 ,  9.2021637 ,  9.19341564,  9.19544601,\n",
       "        9.21889782,  9.21665668,  9.19534874,  9.20263386,  9.22533607,\n",
       "        9.19932747,  9.20866489,  9.20067596,  9.21399593,  9.20217705,\n",
       "        9.22528839,  9.20143032,  9.20847797,  9.19704914,  9.22271061,\n",
       "        9.21421814,  9.21191597,  9.22452545,  9.22636604,  9.21423817,\n",
       "        9.21462154,  9.21042633,  9.19309616,  9.21429634,  9.22619438,\n",
       "        9.21718979,  9.22160435,  9.22699451,  9.21078014,  9.20941639,\n",
       "        9.21346664,  9.2135582 ,  9.20278168,  9.20084953,  9.21110344,\n",
       "        9.20339966,  9.21888638,  9.1952343 ,  9.20177841,  9.20966434,\n",
       "        9.2189455 ,  9.21419144,  9.22155666,  9.20817566,  9.20854282,\n",
       "        9.20564651,  9.21901512,  9.20036793,  9.21412468,  9.20367146,\n",
       "        9.21619415,  9.19487286,  9.21918678,  9.20108414,  9.21315002,\n",
       "        9.20273304,  9.20170784,  9.21287251,  9.2242403 ,  9.22314358,\n",
       "        9.19890118,  9.21391582,  9.2045393 ,  9.19458485,  9.19527435,\n",
       "        9.1939764 ,  9.20932102,  9.20955753,  9.19538784,  9.20003891,\n",
       "        9.2104969 ,  9.20093632,  9.22754574,  9.19538403,  9.21114922,\n",
       "        9.21796703,  9.21258354,  9.19497585,  9.20268631,  9.19379616,\n",
       "        9.22407627,  9.22014236,  9.22341156,  9.21463394,  9.22109509,\n",
       "        9.19903278,  9.21336174,  9.19396019,  9.20961952,  9.2195282 ,\n",
       "        9.19785786,  9.21470833,  9.20263958,  9.22531891,  9.20180035,\n",
       "        9.20697403,  9.21370411,  9.20959949,  9.21080971,  9.20626831,\n",
       "        9.22531891,  9.22712612,  9.20506477,  9.21096039,  9.21343231,\n",
       "        9.21225357,  9.20624733,  9.1988163 ,  9.21342564,  9.19395733,\n",
       "        9.19917107,  9.21543884,  9.21413231,  9.21890545,  9.21185398,\n",
       "        9.21812534,  9.20948601,  9.22360039,  9.21878719,  9.20081615,\n",
       "        9.20265484,  9.21094608,  9.19633961,  9.22531509,  9.19969368,\n",
       "        9.20189571,  9.22574234,  9.22075558,  9.22621346,  9.22010899,\n",
       "        9.22202969,  9.22058678,  9.19714832,  9.21612644,  9.22667503,\n",
       "        9.22721291,  9.19697475,  9.22683811,  9.21937847,  9.19561768,\n",
       "        9.20331001,  9.22011852,  9.1971035 ,  9.21529961,  9.21148586,\n",
       "        9.21411705,  9.19823837,  9.2185421 ,  9.22147846,  9.20191669,\n",
       "        9.21082687,  9.21852875,  9.21866322,  9.22213173,  9.21770763], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(loss, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184.19798"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = tf.reduce_sum(loss) / batch_size\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(cost, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.Variable(0.0, trainable= False)\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding:0' shape=(10000, 200) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(400, 800) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(800,) dtype=float32_ref>,\n",
       " <tf.Variable 'softmax_w:0' shape=(200, 10000) dtype=float32_ref>,\n",
       " <tf.Variable 'softmax_b:0' shape=(10000,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "tvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = tvars[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'softmax_w:0', u'softmax_b:0']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tvars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'truediv:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'softmax_w:0' shape=(200, 10000) dtype=float32_ref>,\n",
       " <tf.Variable 'softmax_b:0' shape=(10000,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toy example (Gradient)\n",
    "var_x = tf.placeholder(tf.float32)\n",
    "var_y = tf.placeholder(tf.float32)\n",
    "func_test = 2.0 * var_x * var_x + 3.0 * var_x * var_y\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed = {var_x: 1.0, var_y: 2.0}\n",
    "sess.run(func_test, feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.0]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_grad = tf.gradients(func_test, [var_x])\n",
    "sess.run(var_grad, feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_grad = tf.gradients(func_test, [var_y])\n",
    "sess.run(var_grad,feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_t_list = tf.gradients(cost, tvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'clip_by_global_norm_1/clip_by_global_norm_1/_0:0' shape=(200, 10000) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm_1/clip_by_global_norm_1/_1:0' shape=(10000,) dtype=float32>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads, _ = tf.clip_by_global_norm(grad_t_list, max_grad_norm)\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  2.94609548e-04,   3.76086682e-04,   1.96285153e-04, ...,\n",
       "          -3.59663971e-07,  -3.58780341e-07,  -3.51121685e-07],\n",
       "        [  1.30369066e-04,   4.24927348e-05,  -1.54847265e-04, ...,\n",
       "          -1.24238426e-07,  -1.23917914e-07,  -1.21292800e-07],\n",
       "        [  2.56144540e-05,   6.01838401e-05,   1.24944621e-04, ...,\n",
       "           1.93276453e-08,   1.92546583e-08,   1.88615648e-08],\n",
       "        ..., \n",
       "        [ -2.55317922e-04,  -2.42163165e-04,  -1.89787257e-04, ...,\n",
       "           3.97985531e-07,   3.97018511e-07,   3.88513627e-07],\n",
       "        [  1.62385659e-05,   1.15497482e-04,   8.28100019e-05, ...,\n",
       "          -8.96525094e-08,  -8.94086298e-08,  -8.75088446e-08],\n",
       "        [ -2.60127854e-04,  -1.99975562e-04,  -2.00370967e-04, ...,\n",
       "           4.68515196e-07,   4.67331489e-07,   4.57362233e-07]], dtype=float32),\n",
       " array([-0.797997  , -1.03135109, -1.03133023, ...,  0.00201682,\n",
       "         0.00201183,  0.00196875], dtype=float32)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(grads, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = optimizer.apply_gradients(zip(grads, tvars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(train_op, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PTBModel(object):\n",
    "\n",
    "    def __init__(self, is_training):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_steps = num_steps\n",
    "        size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self._input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n",
    "        self._targets = tf.placeholder(tf.int32, [batch_size, num_steps])\n",
    "\n",
    "        lstm_cell = tf.contrib.rnn.BasicLSTMCell(size, forget_bias=0.0)\n",
    "\n",
    "        if is_training and keep_prob < 1:\n",
    "            lstm_cell = tf.contrib.rnn.DropoutWrapper(lstm_cell, output_keep_prob=keep_prob)\n",
    "        \n",
    "        stacked_lstm = tf.contrib.rnn.MultiRNNCell([lstm_cell] * num_layers)\n",
    "\n",
    "        self._initial_state = stacked_lstm.zero_state(batch_size, tf.float32)\n",
    "\n",
    "        with tf.device(\"/gpu:0\"):\n",
    "            embedding = tf.get_variable(\"embedding\", [vocab_size, size])\n",
    "            inputs = tf.nn.embedding_lookup(embedding, self._input_data)\n",
    "\n",
    "        if is_training and keep_prob < 1:\n",
    "            inputs = tf.nn.dropout(inputs, keep_prob)\n",
    "\n",
    "        outputs, state = tf.nn.dynamic_rnn(stacked_lstm, inputs, initial_state=self._initial_state)\n",
    "\n",
    "        output = tf.reshape(outputs, [-1, size])\n",
    "        softmax_w = tf.get_variable(\"softmax_w\", [size, vocab_size])\n",
    "        softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "        logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "\n",
    "        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits], [tf.reshape(self._targets, [-1])],\n",
    "                                                      [tf.ones([batch_size * num_steps])])\n",
    "        self._cost = cost = tf.reduce_sum(loss) / batch_size\n",
    "\n",
    "        self._final_state = state\n",
    "\n",
    "        if not is_training:\n",
    "            return\n",
    "\n",
    "        self._lr = tf.Variable(0.0, trainable=False)\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), max_grad_norm)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(self.lr)\n",
    "        self._train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "    # Helper functions for our LSTM RNN class\n",
    "\n",
    "    def assign_lr(self, session, lr_value):\n",
    "        session.run(tf.assign(self.lr, lr_value))\n",
    "\n",
    "    @property\n",
    "    def input_data(self):\n",
    "        return self._input_data\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return self._targets\n",
    "\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        return self._initial_state\n",
    "\n",
    "    @property\n",
    "    def cost(self):\n",
    "        return self._cost\n",
    "\n",
    "    @property\n",
    "    def final_state(self):\n",
    "        return self._final_state\n",
    "\n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self._lr\n",
    "\n",
    "    @property\n",
    "    def train_op(self):\n",
    "        return self._train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(session, m, data, eval_op, verbose=False):\n",
    "\n",
    "    epoch_size = ((len(data) // m.batch_size) - 1) // m.num_steps\n",
    "    start_time = time.time()\n",
    "    costs = 0.0\n",
    "    iters = 0\n",
    "\n",
    "    state = session.run(m.initial_state)\n",
    "    \n",
    "    for step, (x, y) in enumerate(reader.ptb_iterator(data, m.batch_size, m.num_steps)):\n",
    " \n",
    "        cost, state, _ = session.run([m.cost, m.final_state, eval_op],\n",
    "                                     {m.input_data: x,\n",
    "                                      m.targets: y,\n",
    "                                      m.initial_state: state})\n",
    "        \n",
    "        costs += cost\n",
    "        \n",
    "        iters += m.num_steps\n",
    "\n",
    "        if verbose and step % (epoch_size // 10) == 10:\n",
    "            print(\"%.3f perplexity: %.3f speed: %.0f wps\" % (step * 1.0 / epoch_size, np.exp(costs / iters),\n",
    "              iters * m.batch_size / (time.time() - start_time)))\n",
    "\n",
    "    return np.exp(costs / iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = reader.ptb_raw_data(data_dir)\n",
    "train_data, valid_data, test_data, _ = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Learning rate: 1.000\n",
      "0.006 perplexity: 5884.353 speed: 30755 wps\n",
      "0.106 perplexity: 1068.353 speed: 34392 wps\n",
      "0.205 perplexity: 814.324 speed: 35183 wps\n",
      "0.305 perplexity: 664.918 speed: 35226 wps\n",
      "0.404 perplexity: 560.777 speed: 35319 wps\n",
      "0.504 perplexity: 495.421 speed: 35475 wps\n",
      "0.603 perplexity: 445.998 speed: 35379 wps\n",
      "0.702 perplexity: 409.485 speed: 34984 wps\n",
      "0.802 perplexity: 381.497 speed: 34994 wps\n",
      "0.901 perplexity: 355.566 speed: 35054 wps\n",
      "Epoch 1 : Train Perplexity: 335.193\n",
      "Epoch 1 : Valid Perplexity: 200.443\n",
      "Epoch 2 : Learning rate: 1.000\n",
      "0.006 perplexity: 223.254 speed: 30751 wps\n",
      "0.106 perplexity: 198.062 speed: 35125 wps\n",
      "0.205 perplexity: 190.227 speed: 34613 wps\n",
      "0.305 perplexity: 182.438 speed: 34566 wps\n",
      "0.404 perplexity: 174.148 speed: 34506 wps\n",
      "0.504 perplexity: 170.804 speed: 34518 wps\n",
      "0.603 perplexity: 167.147 speed: 34514 wps\n",
      "0.702 perplexity: 164.015 speed: 34619 wps\n",
      "0.802 perplexity: 161.778 speed: 34810 wps\n",
      "0.901 perplexity: 157.913 speed: 34954 wps\n",
      "Epoch 2 : Train Perplexity: 155.244\n",
      "Epoch 2 : Valid Perplexity: 155.857\n",
      "Epoch 3 : Learning rate: 1.000\n",
      "0.006 perplexity: 153.333 speed: 30642 wps\n",
      "0.106 perplexity: 139.656 speed: 34737 wps\n",
      "0.205 perplexity: 136.111 speed: 34995 wps\n",
      "0.305 perplexity: 131.818 speed: 34825 wps\n",
      "0.404 perplexity: 127.051 speed: 34994 wps\n",
      "0.504 perplexity: 126.047 speed: 35152 wps\n",
      "0.603 perplexity: 124.400 speed: 35126 wps\n",
      "0.702 perplexity: 123.003 speed: 35292 wps\n",
      "0.802 perplexity: 122.190 speed: 35313 wps\n",
      "0.901 perplexity: 120.018 speed: 35241 wps\n",
      "Epoch 3 : Train Perplexity: 118.809\n",
      "Epoch 3 : Valid Perplexity: 141.759\n",
      "Epoch 4 : Learning rate: 1.000\n",
      "0.006 perplexity: 123.226 speed: 29063 wps\n",
      "0.106 perplexity: 114.521 speed: 34113 wps\n",
      "0.205 perplexity: 112.616 speed: 34460 wps\n",
      "0.305 perplexity: 109.424 speed: 34498 wps\n",
      "0.404 perplexity: 105.845 speed: 34483 wps\n",
      "0.504 perplexity: 105.410 speed: 34813 wps\n",
      "0.603 perplexity: 104.401 speed: 34818 wps\n",
      "0.702 perplexity: 103.470 speed: 34706 wps\n",
      "0.802 perplexity: 103.126 speed: 34671 wps\n",
      "0.901 perplexity: 101.552 speed: 34889 wps\n",
      "Epoch 4 : Train Perplexity: 100.819\n",
      "Epoch 4 : Valid Perplexity: 135.591\n",
      "Epoch 5 : Learning rate: 1.000\n",
      "0.006 perplexity: 107.531 speed: 27431 wps\n",
      "0.106 perplexity: 100.403 speed: 34968 wps\n",
      "0.205 perplexity: 98.877 speed: 35132 wps\n",
      "0.305 perplexity: 96.101 speed: 34775 wps\n",
      "0.404 perplexity: 93.003 speed: 34792 wps\n",
      "0.504 perplexity: 92.817 speed: 34947 wps\n",
      "0.603 perplexity: 92.084 speed: 34797 wps\n",
      "0.702 perplexity: 91.380 speed: 34863 wps\n",
      "0.802 perplexity: 91.175 speed: 34890 wps\n",
      "0.901 perplexity: 89.889 speed: 34854 wps\n",
      "Epoch 5 : Train Perplexity: 89.369\n",
      "Epoch 5 : Valid Perplexity: 134.637\n",
      "Epoch 6 : Learning rate: 0.500\n",
      "0.006 perplexity: 95.254 speed: 29198 wps\n",
      "0.106 perplexity: 87.364 speed: 33748 wps\n",
      "0.205 perplexity: 84.713 speed: 34454 wps\n",
      "0.305 perplexity: 81.438 speed: 34512 wps\n",
      "0.404 perplexity: 77.904 speed: 34124 wps\n",
      "0.504 perplexity: 76.893 speed: 34071 wps\n",
      "0.603 perplexity: 75.585 speed: 34132 wps\n",
      "0.702 perplexity: 74.355 speed: 34214 wps\n",
      "0.802 perplexity: 73.532 speed: 34258 wps\n",
      "0.901 perplexity: 71.873 speed: 34367 wps\n",
      "Epoch 6 : Train Perplexity: 70.867\n",
      "Epoch 6 : Valid Perplexity: 124.606\n",
      "Epoch 7 : Learning rate: 0.250\n",
      "0.006 perplexity: 78.200 speed: 27494 wps\n",
      "0.106 perplexity: 73.628 speed: 34180 wps\n",
      "0.205 perplexity: 71.585 speed: 34927 wps\n",
      "0.305 perplexity: 68.831 speed: 35241 wps\n",
      "0.404 perplexity: 65.699 speed: 34993 wps\n",
      "0.504 perplexity: 64.765 speed: 34950 wps\n",
      "0.603 perplexity: 63.578 speed: 34796 wps\n",
      "0.702 perplexity: 62.419 speed: 34807 wps\n",
      "0.802 perplexity: 61.559 speed: 34947 wps\n",
      "0.901 perplexity: 60.028 speed: 34831 wps\n",
      "Epoch 7 : Train Perplexity: 59.032\n",
      "Epoch 7 : Valid Perplexity: 123.765\n",
      "Epoch 8 : Learning rate: 0.125\n",
      "0.006 perplexity: 69.940 speed: 27521 wps\n",
      "0.106 perplexity: 66.123 speed: 33921 wps\n",
      "0.205 perplexity: 64.387 speed: 34506 wps\n",
      "0.305 perplexity: 61.906 speed: 34461 wps\n",
      "0.404 perplexity: 59.047 speed: 34404 wps\n",
      "0.504 perplexity: 58.181 speed: 34715 wps\n",
      "0.603 perplexity: 57.086 speed: 34952 wps\n",
      "0.702 perplexity: 55.989 speed: 34887 wps\n",
      "0.802 perplexity: 55.156 speed: 34802 wps\n",
      "0.901 perplexity: 53.737 speed: 34811 wps\n",
      "Epoch 8 : Train Perplexity: 52.797\n",
      "Epoch 8 : Valid Perplexity: 124.200\n",
      "Epoch 9 : Learning rate: 0.062\n",
      "0.006 perplexity: 65.660 speed: 27558 wps\n",
      "0.106 perplexity: 62.183 speed: 34846 wps\n",
      "0.205 perplexity: 60.678 speed: 34924 wps\n",
      "0.305 perplexity: 58.347 speed: 35185 wps\n",
      "0.404 perplexity: 55.639 speed: 35255 wps\n",
      "0.504 perplexity: 54.816 speed: 35206 wps\n",
      "0.603 perplexity: 53.780 speed: 35217 wps\n",
      "0.702 perplexity: 52.724 speed: 35156 wps\n",
      "0.802 perplexity: 51.916 speed: 35228 wps\n",
      "0.901 perplexity: 50.557 speed: 35208 wps\n",
      "Epoch 9 : Train Perplexity: 49.643\n",
      "Epoch 9 : Valid Perplexity: 124.364\n",
      "Epoch 10 : Learning rate: 0.031\n",
      "0.006 perplexity: 63.328 speed: 33921 wps\n",
      "0.106 perplexity: 60.123 speed: 34392 wps\n",
      "0.205 perplexity: 58.740 speed: 34372 wps\n",
      "0.305 perplexity: 56.494 speed: 34429 wps\n",
      "0.404 perplexity: 53.866 speed: 34484 wps\n",
      "0.504 perplexity: 53.066 speed: 34533 wps\n",
      "0.603 perplexity: 52.069 speed: 34680 wps\n",
      "0.702 perplexity: 51.033 speed: 34779 wps\n",
      "0.802 perplexity: 50.238 speed: 34722 wps\n",
      "0.901 perplexity: 48.908 speed: 34844 wps\n",
      "Epoch 10 : Train Perplexity: 48.010\n",
      "Epoch 10 : Valid Perplexity: 124.373\n",
      "Epoch 11 : Learning rate: 0.016\n",
      "0.006 perplexity: 62.039 speed: 28086 wps\n",
      "0.106 perplexity: 59.018 speed: 34061 wps\n",
      "0.205 perplexity: 57.686 speed: 35006 wps\n",
      "0.305 perplexity: 55.491 speed: 35470 wps\n",
      "0.404 perplexity: 52.903 speed: 35476 wps\n",
      "0.504 perplexity: 52.117 speed: 35495 wps\n",
      "0.603 perplexity: 51.143 speed: 35460 wps\n",
      "0.702 perplexity: 50.121 speed: 35317 wps\n",
      "0.802 perplexity: 49.330 speed: 35369 wps\n",
      "0.901 perplexity: 48.015 speed: 35231 wps\n",
      "Epoch 11 : Train Perplexity: 47.126\n",
      "Epoch 11 : Valid Perplexity: 124.318\n",
      "Epoch 12 : Learning rate: 0.008\n",
      "0.006 perplexity: 61.316 speed: 29097 wps\n",
      "0.106 perplexity: 58.409 speed: 34326 wps\n",
      "0.205 perplexity: 57.101 speed: 35169 wps\n",
      "0.305 perplexity: 54.937 speed: 35115 wps\n",
      "0.404 perplexity: 52.373 speed: 35037 wps\n",
      "0.504 perplexity: 51.595 speed: 35082 wps\n",
      "0.603 perplexity: 50.633 speed: 35082 wps\n",
      "0.702 perplexity: 49.621 speed: 34847 wps\n",
      "0.802 perplexity: 48.832 speed: 34778 wps\n",
      "0.901 perplexity: 47.525 speed: 34690 wps\n",
      "Epoch 12 : Train Perplexity: 46.640\n",
      "Epoch 12 : Valid Perplexity: 124.171\n",
      "Epoch 13 : Learning rate: 0.004\n",
      "0.006 perplexity: 60.876 speed: 29508 wps\n",
      "0.106 perplexity: 58.064 speed: 32899 wps\n",
      "0.205 perplexity: 56.776 speed: 33689 wps\n",
      "0.305 perplexity: 54.633 speed: 34296 wps\n",
      "0.404 perplexity: 52.083 speed: 34508 wps\n",
      "0.504 perplexity: 51.309 speed: 34387 wps\n",
      "0.603 perplexity: 50.353 speed: 34403 wps\n",
      "0.702 perplexity: 49.348 speed: 34370 wps\n",
      "0.802 perplexity: 48.560 speed: 34508 wps\n",
      "0.901 perplexity: 47.258 speed: 34619 wps\n",
      "Epoch 13 : Train Perplexity: 46.375\n",
      "Epoch 13 : Valid Perplexity: 123.969\n",
      "Test Perplexity: 117.764\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    initializer = tf.random_uniform_initializer(-init_scale,init_scale)\n",
    "    \n",
    "    with tf.variable_scope(\"model\", reuse=None, initializer=initializer):\n",
    "        m = PTBModel(is_training=True)\n",
    "        \n",
    "    with tf.variable_scope(\"model\", reuse=True, initializer=initializer):\n",
    "        mvalid = PTBModel(is_training=False)\n",
    "        mtest = PTBModel(is_training=False)\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    for i in range(max_max_epoch):\n",
    "        lr_decay = decay ** max(i - max_epoch, 0.0)\n",
    "        \n",
    "        m.assign_lr(session, learning_rate * lr_decay)\n",
    "\n",
    "        print(\"Epoch %d : Learning rate: %.3f\" % (i + 1, session.run(m.lr)))\n",
    "        \n",
    "        train_perplexity = run_epoch(session, m, train_data, m.train_op,\n",
    "                                   verbose=True)\n",
    "        print(\"Epoch %d : Train Perplexity: %.3f\" % (i + 1, train_perplexity))\n",
    "        \n",
    "        valid_perplexity = run_epoch(session, mvalid, valid_data, tf.no_op())\n",
    "        print(\"Epoch %d : Valid Perplexity: %.3f\" % (i + 1, valid_perplexity))\n",
    "    \n",
    "    test_perplexity = run_epoch(session, mtest, test_data, tf.no_op())\n",
    "    \n",
    "    print(\"Test Perplexity: %.3f\" % test_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
